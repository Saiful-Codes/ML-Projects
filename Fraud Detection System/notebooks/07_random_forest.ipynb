{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36857530",
   "metadata": {},
   "source": [
    "# Week 10 â€” Day 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c6eaa8",
   "metadata": {},
   "source": [
    "### Imports + load split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6c2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score, f1_score, average_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c111f7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (227845, 30) (227845,)\n",
      "Test: (56962, 30) (56962,)\n"
     ]
    }
   ],
   "source": [
    "ARTIFACTS_DIR = Path(\"..\") / \"models\"\n",
    "REPORTS_DIR = Path(\"..\") / \"reports\"\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = joblib.load(ARTIFACTS_DIR / \"split_v1.joblib\")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e631f",
   "metadata": {},
   "source": [
    "### Reusing Feature Engineering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31fca3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"log_amount\"] = np.log1p(df[\"Amount\"])\n",
    "    df[\"hour\"] = (df[\"Time\"] // 3600).astype(int)\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8ee735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (227845, 30) After: (227845, 34)\n"
     ]
    }
   ],
   "source": [
    "# applying features\n",
    "X_train_fe = add_features(X_train)\n",
    "X_test_fe = add_features(X_test)\n",
    "\n",
    "print(\"Before:\", X_train.shape, \"After:\", X_train_fe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea9dfc",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4063658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")\n",
    "\n",
    "rf.fit(X_train_fe, y_train)\n",
    "print(\"Random Forest trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf5c29",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca83ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and scores\n",
    "y_pred = rf.predict(X_test_fe)\n",
    "y_prob = rf.predict_proba(X_test_fe)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a9f44e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (tn, fp, fn, tp): 56861 3 25 73\n",
      "Precision: 0.960526\n",
      "Recall:    0.744898\n",
      "F1:        0.839080\n",
      "PR-AUC:    0.865561\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "pr_auc = average_precision_score(y_test, y_prob)\n",
    "\n",
    "print(\"Confusion matrix (tn, fp, fn, tp):\", tn, fp, fn, tp)\n",
    "print(f\"Precision: {precision:.6f}\")\n",
    "print(f\"Recall:    {recall:.6f}\")\n",
    "print(f\"F1:        {f1:.6f}\")\n",
    "print(f\"PR-AUC:    {pr_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1f9991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg Baseline</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.716763</td>\n",
       "      <td>0.741382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg + Class Weights</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.114358</td>\n",
       "      <td>0.718971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg + FE + Class Weights</td>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.720672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest + FE</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>0.865561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  precision    recall        f1    pr_auc\n",
       "0              LogReg Baseline   0.826667  0.632653  0.716763  0.741382\n",
       "1       LogReg + Class Weights   0.060976  0.918367  0.114358  0.718971\n",
       "2  LogReg + FE + Class Weights   0.059840  0.918367  0.112360  0.720672\n",
       "3           Random Forest + FE   0.960526  0.744898  0.839080  0.865561"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison table \n",
    "week9_baseline = {\"model\": \"LogReg Baseline\", \"precision\": 0.826667, \"recall\": 0.632653, \"f1\": 0.716763, \"pr_auc\": 0.741382}\n",
    "week9_weighted = {\"model\": \"LogReg + Class Weights\", \"precision\": 0.060976, \"recall\": 0.918367, \"f1\": 0.114358, \"pr_auc\": 0.718971}\n",
    "week10_fe_weighted = {\"model\": \"LogReg + FE + Class Weights\", \"precision\": 0.059840, \"recall\": 0.918367, \"f1\": 0.112360, \"pr_auc\": 0.720672}\n",
    "\n",
    "week10_rf = {\"model\": \"Random Forest + FE\", \"precision\": precision, \"recall\": recall, \"f1\": f1, \"pr_auc\": pr_auc}\n",
    "\n",
    "compare_df = pd.DataFrame([week9_baseline, week9_weighted, week10_fe_weighted, week10_rf])\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d435ad",
   "metadata": {},
   "source": [
    "### Save Table and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be03eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\reports\\week10_day2_random_forest_results.csv\n"
     ]
    }
   ],
   "source": [
    "compare_df.to_csv(REPORTS_DIR / \"week10_day2_random_forest_results.csv\", index=False)\n",
    "print(\"Saved:\", REPORTS_DIR / \"week10_day2_random_forest_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151f32ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\models\\rf_fe_v1.joblib\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(rf, ARTIFACTS_DIR / \"rf_fe_v1.joblib\")\n",
    "print(\"Saved:\", ARTIFACTS_DIR / \"rf_fe_v1.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
